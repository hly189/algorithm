\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsxtra}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[]{mcode}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[margin=1.5cm]{geometry}
\usepackage{url}

\newcommand{\tab}{\hspace{5mm}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{cor}[theorem]{Corrolary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{alg}[theorem]{Algorithm}

\newtheorem*{ex}{Examples:}
\newtheorem*{definition}{Defintion}
\newtheorem*{remarks}{Remarks}


\title{Numerical methods }
\author{Hoa Ly}

\begin{document}

\maketitle
\abstract{ All the numerical methods below base on the lecture notes  of Math 128A (Spring 2014) and Math 128B (Spring 2015). However, most of the codes in this file are written by me. The source code is at https://github.com/hly189.}
\tableofcontents
\newpage

\section{The Bisection method}
\begin{alg}
\begin{itemize}
	\item Suppose $f$ is continous on $[a,b]$, and $f(a),f(b)$ is opposite signs.
	\item By Intermediate Value Theorem, there exists $x \in [a,b]$ such that $f(x) = 0$
	\item Find the midpoint $p$ by dividing the interval $[a,b]$ by $p = \frac{a+b}{2}$
	\item If $f(p)$ has the same sign as $f(a)$, we use the new interval $[p,b]$
	\item If $f(p)$ has the same sign as $f(a)$, we use the new interval $[a,p]$
	\item Repeat until the interval small enough to estimate $x$
	\lstinputlisting{/Users/lythaihoa2311992/Desktop/job/algorithm/bisection.m}
\end{itemize}
\end{alg}


\section{Fix-point Iteration}
\subsection{Fixed point} \begin{itemize}
	\item A number $p$ is a fixed point for a given function $g$ if $g(p) = p$
	\item Given a root finding problem $f(p) = 0$, there are many $g$ with fixed point at $p$
	$$g(x) = x - f(x)$$ $$g(x) = x + 3f(x)$$
	\item If $g$ has a fixed point at $p$, then $f(x) = x -g(x)$ has a zero at $p$
\end{itemize}
Fix-point iteration implements the fixed point of iterated function \\ 
\begin{alg}(Fixed-point iteration) \\
Choose an initial guess $x_0 \in [a,b]$
\begin{algorithmic}
\For{k = 0,1,2,... do}
\State $x_{k+1} = g(x_k)$
\If{$|x_{k+1} - x_k|$ is very small then}
\State $x* = x_{k+1}$
\State \Return $x*$
\EndIf
\EndFor
\end{algorithmic}
\lstinputlisting{/Users/lythaihoa2311992/Documents/MATLAB/fixedpoint.m}
\end{alg}



\section{Newton method}
Newton's method is fixed point iteration $p_n = g(p_{n-1})$ with $$g(x) = x - \frac{f(x)}{f'(x)}$$
\begin{alg}{Newton-algorithm}
\begin{algorithmic}
Choose an initial guess for $x_0$
\For{x = 1,2,...k}
\State $x* = x_{k}$
\State $x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}$
\If{$|x_{k+1} - x_k|$ is really small}
\State $x* = x_{k+1}$
\State \Return x*
\EndIf
\EndFor	
\end{algorithmic}
The code below is written in R.
\lstinputlisting{/Users/lythaihoa2311992/R-files/newton.R}	
\end{alg}

\section{Aitken's $\Delta^2$ method}
\subsection{Accelerating convergence}
\begin{itemize}
	\item Suppose $\{p_n\}_{n=0}^{\infty}$ is linearyly convergent with limit $p$
	\item Assume that $$\frac{p_{n+1}-p}{p_n -p} = \frac{p_{n+2}-p}{p_{n+1} -p}$$
	\item Solving for $p$ gives: $$p = \frac{p_{n+2}p_n-p_{n+1}^2}{p_{n+2} -2p_{n+1}+p_n}$$
	\item Use this for new more rapidly converging sequence $\{\hat{p}\}_{n=0}^2$: $$\hat{p} = p_n -\frac{(p_{n+1} -p_n)^2}{p_{n+1} -2p_{n+1} +p_n}$$
\end{itemize}

\subsection{Delta notation}
\begin{definition}
	For a given sequence $\{p_n\}_{n=0}^{\infty}$, the forward difference $\Delta p_n$ is defined by:
	$$\Delta p_n = p_{n+1} - p_n \; \text{for $n \geq 0$}$$
	Higher power of the operator $Delta$ are defined recursively by $$\Delta^kp_n = \Delta(\Delta^{k-1}p_n) \; \text{for $k \geq 2$}$$
	\end{definition}
Since $\Delta^2p_n = p_{n+2} -2p_{n+1} + p_n$, then $$\hat{p}_n = p_n - \frac{(\Delta p_n)^2}{\Delta^2 p_n}$$
\subsection{Convergence of Aitken's $\Delta^2$ Method}
\begin{theorem}
Suppose that $\{p_n\}_{n=0}^{\infty}$ converges linearly to p and that $$\lim_{n \to \infty} \frac{p_{n+1} - p}{p_n - p} <1$$
Then,  	$\{\hat{p}\}_{n=0}^2$ converges to p faster than $\{p_n\}_{n=0}^{\infty}$ in the sense that 
$$\lim_{n \to \infty}\frac{\hat{p}_n -p}{p_n - p} = 0$$
\end{theorem}


\section{Steffensen's Method}
\subsection{Accelerating fixed point iteration}
Aitken's $\Delta^2$ method for fixed-point iteration gives $$p_0, p_1 = g(p_0), \hat{p_0} = \Delta^2p_0$$ $$p3 = g(p_2), \hat{p_1} = \Delta^2p_1, \cdots$$
Steffensen's method assumes $\hat{p_0}$ is better than $p_2$: 
$$p_0^{(0)}, p_1^{(0)} = g(p_0^{(0)}), p_0^{(1)} = \Delta^2(p_0^{(0)})$$ $$p_1^{(1)} = g(p_0^{(1)}), \cdots$$
\begin{alg}{Steffensen's Method}
	\begin{algorithmic}
	Choose an initial guess p0
	\State i =1
	\While{$i \leq N$} where N is the number of iteration
		\State $p_1 = g(p_0)$ (Compute $p_1^{(i-1)}$)
		\State $p_2 = g(p_1)$ (Compute $p_2^{(i-1)}$)
		\State $p = p_0 - \frac{(p_1 - p_0)^2}{p_2 - 2p_1 + p_0}$ (Compute $p_0^{(i)}$)
		\If{$|p - p_0|$ is really small then}
			\State \Return p
		\EndIf
		\State $i = i+1$
		\State $p_0 = p$
		
	\EndWhile
	\State \Return p	
	\end{algorithmic}
\lstinputlisting{/Users/lythaihoa2311992/R-files/Steffensen.R}
\end{alg}


\section{Zeroes Polynomials}

\subsection{Polynomial}
A polynomial of degree n has the form $P(x) = a_nx^n +a_{n-1}x^{n-1} + \cdots +a_1x + a_0$ with coefficient $a_i$ and $a_n \neq 0$
\begin{theorem}{(Fundamental Theorem of Algebra)}
\newline If $P(x)$ polynomial of degree $n \geq 1$, with real or complex coefficients $P(x) = 0$ has at least one root. 	
\end{theorem} 

\begin{cor}
	Exists unique $x_1 \cdots x_k$ and $m_1,\cdots, m_k$ with $\sum_{i=1}^k m_i = n$ and $$P(x) = a_n(x-x_1)^{m_1}(x-x_2)^{m_2}\cdots (x-x_k)^{m_k}$$
\end{cor}

\begin{cor}
$P(x), Q(x)$ polynomials of  degree at most n. If $P(x_i) = Q(x_i)$ for $i = 1,2,\cdots, k$ with $k>n$, then $P(x) = Q(x)$	
\end{cor}


\subsection{Horner's method}
\begin{theorem} {Horner's Method}
\newline Let $P(x) = a_nx^n +a_{n-1}x^{n-1} + \cdots +a_1x + a_0$. If $b_n = a_n$ and $$b_k = a_k +b_{k+1}x_0 \; \text{for $k = n-1, n-2, \cdots, 1,0$}$$
then $b_0 = P(x_0)$. Moreover, if 
$$ Q(x) = b_nx^{n-1} + b_{n-1}x^{n-2} + \cdots + b_2x + b_1$$
then $P(x) = (x - x_0)Q(x) + b_0$
\end{theorem}

\begin{alg}{Horner's }
	\begin{algorithmic}
	Choose an initial guess x0
	\State Set $y = a_n$ and $z = b_n$
	\For{$j = n-1,n-2, \cdots 1$}
	\State $y = x_0y + a_j$
	\State $z = x_0z + y$
	\EndFor	
	\State $y = x_0y + a_0$
	\State \Return y,z
	\end{algorithmic}
	\lstinputlisting{/Users/lythaihoa2311992/R-files/Horner.R}
\end{alg}


\section{Muller's Method}
\begin{itemize}
	\item Similar to Secant method, but parabola instead of line
	\item Fix quadratic polynomial $P(x) = a(x-p_2)^2 +b(x - p_2) + c$ that passes through $(p_0,f(p_0)),(p_1,f(p_1)),(p_2,f(p_2))$.
	\item Solves $P(x) = 0$ for $p_3$ choose root closest to $p_2$:
	$$p_3 = p_2 - \frac{2c}{b + sgn(b)\sqrt{b^2 - 4ac}}$$
	\item Repeat until convergence
	\item Relativey insensitive to initial $p_0,p_1,p_2$ but e.g $f(p_i) = f(p_{i+1}) = f(p_{i+3}) \neq 0 gives problems$
\end{itemize}
\lstinputlisting{/Users/lythaihoa2311992/R-files/muller.R}

\section{The Lagrange Polynomial}
\begin{theorem}
	if $x_0, \cdots , x_n$ distinct and $f$ given at these numbers a unique polynomial $P(x)$ of degree $\leq$ n exists with 
	$$f(x_k) = P(x_k) \; \text{for each $k = 0,1, \cdots, n$}$$
	The polynomial is $$P(x) = f(x_0)L_{n,0}(x) + \cdots + f(x_n)L_{n,n}(x) = \sum_{k=0}^{n}f(x_k)L_{n,k}(x)$$
	where 
	$$L_{n,k}(x) = \frac{(x - x_0)(x - x_1) \cdots (x - x_{k-1})(x - x_{k+1}) \cdots (x- x_n)}{(x_k - x_0)(x_k - x_0)(x_k - x_1) \cdots (x_k - x_{k-1})(x_k - x_{k+1}) \cdots (x_k - x_n)} = \prod_{i \neq k} \frac{(x - x_i)}{(x_k - x_i)}$$
\end{theorem}

\begin{theorem}{(Langrange Polynomial Error Term)}
$x_0, \cdots, x_n$ distinct in $[a,b]$, $f \in C^{n+1}[a,b]$, there exists $\xi (x) \in (a,b)$ with 
$$f(x) = P(x) + \frac{f^{(n+1)}(\xi (x))}{(n+1)!}(x-x_0)(x-x_1) \cdots (x - x_n)$$
where $P(x)$ is the interpolating polynomial. 
\end{theorem}

\section{Neville's Method}
\begin{tabular}{ c c c c c c }
 $x_0$ & $P_0 = Q_{0,0}$ \\
 $x_1$ & $P_1 = Q_{1,0}$ & $P_{0,1} = Q_{1,1}$ \\
 $x_2$ & $P_2 = Q_{2,0}$ & $P_{1,2} = Q_{2,1}$ & $P_{0,1,2} = Q_{2,2}$ \\
 $x_3$ & $P_3 = Q_{3,0}$ & $P_{2,3} = Q_{3,1}$ & $P_{1,2,3} = Q_{3,2}$ & $P_{0,1,2,3} = Q_{3,3}$ \\
 $x_4$ & $P_4 = Q_{4,0}$ & $P_{3,4} = Q_{4,1}$ & $P_{2,3,4} = Q_{4,3}$ & $P_{1,2,3,4} = Q_{4,3}$ & $P_{0,1,2,3,4} = Q_{4,4}$
  \end{tabular}
\begin{alg}{Neville's Iterated Interpolation}
		\begin{algorithmic}
		Choose numbers $x,x_0,x_1 \cdots x_n$; values $f(x_0), f(x_1) \cdots f(x_n)$ as the first column $Q_{0,0}, Q_{1,0}, \cdots Q_{n,0}$ of Q
		\State Create a matrix Q with $P(x) = Q_{n,n}(x)$
		\For{$i = 1,2, \cdots , n$}
		\For{$j = 1,2,\cdots, i$}
		\State $Q_{i,j} = \frac{(x - x_{i-j})Q_{i,j-1} - (x - x_i)Q_{i-1,j-1}}{x_i - x_{i-j}}$
		\EndFor 
		\EndFor	
		\State \Return $Q_{i,j}$
		\end{algorithmic}
	\lstinputlisting{/Users/lythaihoa2311992/R-files/neville.R}

\end{alg}


\section{Divided Difference}
\begin{itemize}
	\item Write the nth Lagrange polynomial in the form: 
	$$P_n(x) = a_0 +a_1(x - x_0) +\cdots a_n(x - x_0)(x - x_1) \cdots (x-x_n)$$
	\item Introduce the $kth$ dived difference
	$$
		f[x_i, x_{i+1}, \cdots x_{i+k-1}, x_{i+k}]  =  \\
		\frac{f[x_i, x_{i+1}, \cdots, x_{i+k}] - f[x_i, x_{i+1}, \cdots x_{i+k-1}]}{x_{i+k} - x_i}
	$$
	\item The coefficients are $a_k = f[x_0,x_1, \cdots x_k]$ and 
	$$P_n(x) = f[x_0] + \sum_{k=1}^{n}a_k(x - x_0) \cdots (x - x_{k-1})$$
\end{itemize}
\begin{alg}{Newton Divided Difference Formula}
\begin{algorithmic}
Choose numbers $x,x_0,x_1 \cdots x_n$; values $f(x_0), f(x_1) \cdots f(x_n)$ as the first column $F_{0,0}, F_{1,0}, \cdots F_{n,0}$ 
\For{$i = 1,2 \cdots n$}
\For{$j = 1,2 \cdots i$}
\State $F_{i,j} = \frac{F_{i,j-1} -F_{i-1,j-1}}{x_i - x_{i-j}}$
\EndFor
\EndFor
\State \Return $F_{i,j}$
\end{algorithmic}

\lstinputlisting{/Users/lythaihoa2311992/R-files/newton_divided_difference.R}
\end{alg}

\section{Hermit's interpolation}
\begin{theorem}
	If $f \in C^1[a,b]$ and $x_0, \cdots, x_n \in [a,b]$ distinct, the Hermite polynomial is 
	$$H_{2n+1}(x) = \sum_{j=0}^n f(x_j)H_{n,j}(x) + \sum_{j=0}^n f'(x_j)\hat{H}_{n,j}(x)$$
	where 
	\begin{eqnarray*}		
	H_{n,j}(x) &=& [1 - 2(x - x_j)L'_{n,j}(x_j)]L^2_{n,j}(x) \\
	\hat{H}_{n,j}(x) &=& (x - x_j)L^2_{n,j}(x)
	\end{eqnarray*}
	Moreover, if $f \in C^{2n+2}[a,b]$, then 
	$$f(x) = H_{2n+1}(x) + \frac{(x - x_0)^2 \cdots (x - x_n)^2}{(2n+2)!}f^{(2n+2)}(\xi(x))$$
	for some $\xi(x) \in (a,b)$
\end{theorem}
\begin{alg}{Hermite Polynomial from Divided Difference}
Suppose $x_0, \cdots, x_n$and $f,f'$ are give at these numbers. Define $z_0, \cdots z_{2n+1}$ by 
$$z_{2i} = z_{2i+1} = x_i$$
Construct divided difference table, but use 
$$f'(x_0), f'(x_1), \cdots f'(x_n)$$
instead of the undefined dived differences 
$$f[z_0,z_1], f[z_2,z_3], \cdots, f[z_{2n},z_{2n+1}]$$
The Hermite polynomial is 
$$H_{2n+1}(x) = f[z_0] +\sum_{k=1}^{2n+1}f[z_0, \cdots z_k](x - z_0) \cdots (x - z_{k-1})$$	
\end{alg}

\lstinputlisting{/Users/lythaihoa2311992/R-files/hermit.R}





 \newpage
 \begin{thebibliography}{1}

      \bibitem{web}Per-olof Persson, \url{https://math.berkeley.edu/~persson/128A/}. Web

  \end{thebibliography}
\end{document}